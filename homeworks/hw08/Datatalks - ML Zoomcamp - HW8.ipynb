{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Homework 8: Hair Type Classification\n",
                "\n",
                "In this homework, we'll build a model for classifying various hair types using a Convolutional Neural Network (CNN) with PyTorch."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup and Data Preparation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "import zipfile\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "import torchvision\n",
                "import torchvision.transforms as transforms\n",
                "from torch.utils.data import DataLoader\n",
                "from torchvision.datasets import ImageFolder\n",
                "import urllib.request\n",
                "\n",
                "# Set random seed for reproducibility\n",
                "SEED = 42\n",
                "np.random.seed(SEED)\n",
                "torch.manual_seed(SEED)\n",
                "if torch.cuda.is_available():\n",
                "    torch.cuda.manual_seed(SEED)\n",
                "    torch.cuda.manual_seed_all(SEED)\n",
                "torch.backends.cudnn.deterministic = True\n",
                "torch.backends.cudnn.benchmark = False"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def download_and_unzip_data():\n",
                "    url = \"https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip\"\n",
                "    filename = \"data.zip\"\n",
                "    if not os.path.exists(filename):\n",
                "        print(f\"Downloading {filename}...\")\n",
                "        urllib.request.urlretrieve(url, filename)\n",
                "    \n",
                "    if not os.path.exists(\"data\"):\n",
                "        print(f\"Unzipping {filename}...\")\n",
                "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
                "            zip_ref.extractall(\".\")\n",
                "\n",
                "download_and_unzip_data()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Data Loading and Transformation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_data_loaders(augment=False):\n",
                "    train_transform_list = [\n",
                "        transforms.Resize((200, 200)),\n",
                "        transforms.ToTensor(),\n",
                "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
                "    ]\n",
                "    \n",
                "    if augment:\n",
                "        train_transform_list = [\n",
                "            transforms.RandomRotation(50),\n",
                "            transforms.RandomResizedCrop(200, scale=(0.9, 1.0), ratio=(0.9, 1.1)),\n",
                "            transforms.RandomHorizontalFlip(),\n",
                "        ] + train_transform_list\n",
                "\n",
                "    train_transforms = transforms.Compose(train_transform_list)\n",
                "\n",
                "    test_transforms = transforms.Compose([\n",
                "        transforms.Resize((200, 200)),\n",
                "        transforms.ToTensor(),\n",
                "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
                "    ])\n",
                "\n",
                "    train_dataset = ImageFolder('./data/train', transform=train_transforms)\n",
                "    test_dataset = ImageFolder('./data/test', transform=test_transforms)\n",
                "\n",
                "    train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True, num_workers=2)\n",
                "    test_loader = DataLoader(test_dataset, batch_size=20, shuffle=False, num_workers=2)\n",
                "\n",
                "    return train_loader, test_loader, len(train_dataset), len(test_dataset)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Model Definition"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class HairNet(nn.Module):\n",
                "    def __init__(self):\n",
                "        super(HairNet, self).__init__()\n",
                "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3)\n",
                "        self.relu = nn.ReLU()\n",
                "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
                "        self.flatten = nn.Flatten()\n",
                "        \n",
                "        # Calculate size after conv and pool\n",
                "        # Input: 200x200\n",
                "        # Conv (3x3): 198x198\n",
                "        # Pool (2x2): 99x99\n",
                "        self.fc1 = nn.Linear(32 * 99 * 99, 64)\n",
                "        self.fc2 = nn.Linear(64, 1)\n",
                "\n",
                "    def forward(self, x):\n",
                "        x = self.pool(self.relu(self.conv1(x)))\n",
                "        x = self.flatten(x)\n",
                "        x = self.relu(self.fc1(x))\n",
                "        x = self.fc2(x)\n",
                "        return x"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Training Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_model(model, train_loader, test_loader, train_len, test_len, num_epochs=10, optimizer=None, criterion=None, device='cpu'):\n",
                "    history = {'acc': [], 'loss': [], 'val_acc': [], 'val_loss': []}\n",
                "    \n",
                "    if optimizer is None:\n",
                "        optimizer = optim.SGD(model.parameters(), lr=0.002, momentum=0.8)\n",
                "    if criterion is None:\n",
                "        criterion = nn.BCEWithLogitsLoss()\n",
                "\n",
                "    for epoch in range(num_epochs):\n",
                "        model.train()\n",
                "        running_loss = 0.0\n",
                "        correct_train = 0\n",
                "        total_train = 0\n",
                "        \n",
                "        for images, labels in train_loader:\n",
                "            images, labels = images.to(device), labels.to(device)\n",
                "            labels = labels.float().unsqueeze(1)\n",
                "\n",
                "            optimizer.zero_grad()\n",
                "            outputs = model(images)\n",
                "            loss = criterion(outputs, labels)\n",
                "            loss.backward()\n",
                "            optimizer.step()\n",
                "\n",
                "            running_loss += loss.item() * images.size(0)\n",
                "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
                "            total_train += labels.size(0)\n",
                "            correct_train += (predicted == labels).sum().item()\n",
                "\n",
                "        epoch_loss = running_loss / train_len\n",
                "        epoch_acc = correct_train / total_train\n",
                "        history['loss'].append(epoch_loss)\n",
                "        history['acc'].append(epoch_acc)\n",
                "\n",
                "        model.eval()\n",
                "        val_running_loss = 0.0\n",
                "        correct_val = 0\n",
                "        total_val = 0\n",
                "        with torch.no_grad():\n",
                "            for images, labels in test_loader:\n",
                "                images, labels = images.to(device), labels.to(device)\n",
                "                labels = labels.float().unsqueeze(1)\n",
                "\n",
                "                outputs = model(images)\n",
                "                loss = criterion(outputs, labels)\n",
                "\n",
                "                val_running_loss += loss.item() * images.size(0)\n",
                "                predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
                "                total_val += labels.size(0)\n",
                "                correct_val += (predicted == labels).sum().item()\n",
                "\n",
                "        val_epoch_loss = val_running_loss / test_len\n",
                "        val_epoch_acc = correct_val / total_val\n",
                "        history['val_loss'].append(val_epoch_loss)\n",
                "        history['val_acc'].append(val_epoch_acc)\n",
                "\n",
                "        print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
                "              f\"Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, \"\n",
                "              f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\")\n",
                "              \n",
                "    return history"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Execution and Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"Using device: {device}\")\n",
                "\n",
                "# Initialize model\n",
                "model = HairNet().to(device)\n",
                "\n",
                "# Question 1: Loss function\n",
                "print(\"\\nQuestion 1: Which loss function you will use?\")\n",
                "print(\"Answer: nn.BCEWithLogitsLoss()\")\n",
                "\n",
                "# Question 2: Total parameters\n",
                "total_params = sum(p.numel() for p in model.parameters())\n",
                "print(f\"\\nQuestion 2: Total parameters: {total_params}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training without augmentation\n",
                "print(\"\\nStarting training (no augmentation)...\")\n",
                "train_loader, test_loader, train_len, test_len = get_data_loaders(augment=False)\n",
                "criterion = nn.BCEWithLogitsLoss()\n",
                "optimizer = optim.SGD(model.parameters(), lr=0.002, momentum=0.8)\n",
                "\n",
                "history = train_model(model, train_loader, test_loader, train_len, test_len, num_epochs=10, optimizer=optimizer, criterion=criterion, device=device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Question 3: Median of training accuracy\n",
                "median_acc = np.median(history['acc'])\n",
                "print(f\"\\nQuestion 3: Median of training accuracy: {median_acc:.2f}\")\n",
                "\n",
                "# Question 4: Standard deviation of training loss\n",
                "std_loss = np.std(history['loss'])\n",
                "print(f\"Question 4: Standard deviation of training loss: {std_loss:.3f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training with augmentation\n",
                "print(\"\\nStarting training (with augmentation)...\")\n",
                "# Note: We continue training the SAME model\n",
                "train_loader_aug, test_loader_aug, train_len_aug, test_len_aug = get_data_loaders(augment=True)\n",
                "\n",
                "history_aug = train_model(model, train_loader_aug, test_loader_aug, train_len_aug, test_len_aug, num_epochs=10, optimizer=optimizer, criterion=criterion, device=device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Question 5: Mean of test loss for all epochs (trained with augmentations)\n",
                "mean_val_loss_aug = np.mean(history_aug['val_loss'])\n",
                "print(f\"\\nQuestion 5: Mean of test loss (augmented): {mean_val_loss_aug:.3f}\")\n",
                "\n",
                "# Question 6: Average of test accuracy for the last 5 epochs (6 to 10)\n",
                "avg_val_acc_last_5 = np.mean(history_aug['val_acc'][5:])\n",
                "print(f\"Question 6: Average of test accuracy for the last 5 epochs: {avg_val_acc_last_5:.2f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Answers\n",
                "\n",
                "question 1 is nn.BCEWithLogitsLoss()\n",
                "\n",
                "question 2 is 20073473\n",
                "\n",
                "question 3 is 0.84\n",
                "\n",
                "question 4 is 0.171\n",
                "\n",
                "question 5 is 0.88\n",
                "\n",
                "question 6 is 0.68"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
